<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Blog - Personal website</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Template Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,600i,700" rel="stylesheet">

    <!-- Template CSS Files -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/preloader.min.css" rel="stylesheet">
    <link href="css/circle.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fm.revealator.jquery.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <!-- CSS Skin File -->
    <link href="css/skins/magenta.css" rel="stylesheet">

    <!-- Modernizr JS File -->
    <script src="js/modernizr.custom.js"></script>
</head>

<body class="publications light">
<!-- Header Starts -->
<header class="header" id="navbar-collapse-toggle">
    <!-- Fixed Navigation Starts -->
    <ul class="icon-menu d-none d-lg-block revealator-slideup revealator-once revealator-delay1">
        <li class="icon-box">
            <i class="fa fa-home"></i>
            <a href="index.html">
                <h2>Home</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-user"></i>
            <a href="about.html">
                <h2>About</h2>
            </a>
        </li>
        <li class="icon-box active">
            <i class="fa fa-book"></i>
            <a href=publications.html>
                <h2>Publications</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-briefcase"></i>
            <a href="portfolio.html">
                <h2>Portfolio</h2>
            </a>
        </li>
        <li class="icon-box">
            <i class="fa fa-envelope-open"></i>
            <a href="contact.html">
                <h2>Contact</h2>
            </a>
        </li>
    </ul>
    <!-- Fixed Navigation Ends -->
    <!-- Mobile Menu Starts -->
    <nav role="navigation" class="d-block d-lg-none">
        <div id="menuToggle">
            <input type="checkbox" />
            <span></span>
            <span></span>
            <span></span>
            <ul class="list-unstyled" id="menu">
                <li><a href="index.html"><i class="fa fa-home"></i><span>Home</span></a></li>
                <li><a href="about.html"><i class="fa fa-user"></i><span>About</span></a></li>
                <li class="active"><a href=publications.html><i class="fa fa-book"></i><span>Publications</span></a></li>
                <li><a href="portfolio.html"><i class="fa fa-folder-open"></i><span>Portfolio</span></a></li>
                <li><a href="contact.html"><i class="fa fa-envelope-open"></i><span>Contact</span></a></li>
            </ul>
        </div>
    </nav>
    <!-- Mobile Menu Ends -->
</header>
<!-- Header Ends -->
<!-- Page Title Starts -->
<section class="title-section text-left text-sm-center revealator-slideup revealator-once revealator-delay1">
    <h1>my <span>publications</span></h1>
    <!-- <span class="title-bg">posts</span> -->
</section>
<!-- Page Title Ends -->
<!-- Main Content Starts -->
<section class="main-content revealator-slideup revealator-once revealator-delay1">
    <div class="container">
        <!-- Articles Starts -->
        <div class="row">
            <!-- Article Starts -->
            <div class="col-12 col-md-6 col-lg-6 col-xl-4 mb-30">
                <article class="post-container">
                    <div class="post-thumb">
                        <a class="d-block position-relative overflow-hidden" href="assets/publications/IEEE_access_first_version.pdf" download>
                            <img src="assets/publications/IEEE_access-diagonal_tensor.png" class="img-fluid" alt="Blog Post">
                        </a>
                    </div>
                    <div class="post-content">
                        <div class="entry-header">
                            <h3><a href="assets/publications/IEEE_access_first_version.pdf" download>IEEE Access | Joint Factors And Rank Estimation For The Canonical Polyadic Decomposition Based On Convex Optimization</a></h3>
                        </div>
                        <div class="entry-content open-sans-font">
														<p><span class="author">KARMOUDA, O.</span>, <span class="author">BOULANGER, J.</span>, & <span class="author">BOYER, R.</span> Joint Factors And Rank Canonical Estimation For The Polyadic Decomposition Based On Convex Optimization, IEEE Acess 2022.</p>

                            <p>
															<b>Abstract:</b> Estimating the minimal number of rank-$1$ tensors in the Canonical Polyadic Decomposition (CPD), known as the canonical rank, is a challenging area of research.
															<br/> <br/> To address this problem, we propose a method based on convex optimization to jointly estimate the CP factors and the canonical rank called FARAC for joint FActors and RAnk canonical estimation for the PolyadiC Decomposition.
															<br/> <br/> We formulate the FARAC method as a convex optimization problem in which a sparse promoting constraint is added to the super diagonal of the core tensor of the CPD, whereas the Frobenius norm of the off-diagonal terms is constrained to be bounded.
															<br/> <br/> We propose an alternated minimization strategy for the Lagrangien to solve the optimization problem. \textcolor{black}{The FARAC method has been validated on synthetic data with varying levels of noise, as well as on three real data sets.}
															<br/> <br/> Compared to state-of-the-art methods, FARAC exhibits very good performance in terms of rank estimation accuracy for a large range of SNR values. Additionally, FARAC can handle the case in which the canonical rank exceeds one of the dimensions of the input tensor.
														</p>
                        </div>
                    </div>
                </article>
            </div>
            <!-- Article Ends -->
            <!-- Article Starts -->
            <div class="col-12 col-md-6 col-lg-6 col-xl-4 mb-30">
                <article class="post-container">
                    <div class="post-thumb">
											<a class="d-block position-relative overflow-hidden" href="assets/publications/EUSIPCO2022.pdf" download>
												<img src="assets/publications/EUSIPCO2022-TT_fig_cl.png" class="img-fluid" alt="Blog Post">
											</a>
                    </div>
                    <div class="post-content">
                        <div class="entry-header">
                            <h3><a href="assets/publications/EUSIPCO2022.pdf" download>EUSIPCO2022 | High-Dimensional Data Learning Based on Tensorial-Singular Space of Tensor Train Cores.</a></h3>
                        </div>
                        <div class="entry-content open-sans-font">
                            <p><span class="author">KARMOUDA, O.</span>, <span class="author">BOYER, R.</span>, & <span class="author">BOULANGER, J.</span> High-Dimensional Data Learning Based on Tensorial-Singular Space of Tensor Train Cores, EUSIPCO 2022.</p>

														<p>
															<b>Abstract:</b> Tensors are multidimensional data structures used to represent many real-world data. In the context of supervised learning, Support Vector Machines (SVMs) are known to be very efficient for different classification tasks.
															<br/> <br/> In this work, we propose a kernel metric for SVM to deal with nonlinear classification problems. First, we use the Tensor Train Decomposition (TTD) to decompose a tensor into  TT-cores of order three and two matrices.
															<br/> <br/> In order to mitigate the problem of non-uniqueness of TTD, we propose a kernel based on the tensorial singular subspaces spanned by TT-cores. The TT-based kernel function proposed is based on the tools of t-Algebra of $3$-rd order tensors. We also show that using different kernel functions on each TT-core is possible. Numerical experiments on real-world datasets show the competitivity of our approach compared to existing methods and the superiority of our method when dealing with a few-sample of high-dimensional inputs.
														</p>
                        </div>
                    </div>
                </article>
            </div>
            <!-- Article Ends -->
            <!-- Article Starts -->
            <div class="col-12 col-md-6 col-lg-6 col-xl-4 mb-30">
                <article class="post-container">
                    <div class="post-thumb">
                        <a class="d-block position-relative overflow-hidden" href="assets/publications/ICASSP21.pdf" download>
                            <img src="assets//publications/ICASSP2021-angle_v4.png" class="img-fluid" alt="Blog Post">
                        </a>
                    </div>
                    <div class="post-content">
                        <div class="entry-header">
                            <h3><a href="assets/publications/ICASSP21.pdf" download>ICASSP2021 | Speeding Up Of Kernel-Based Learning For High-OrderTensors.</a></h3>
                        </div>
                        <div class="entry-content open-sans-font">
                            <p><span class="author">KARMOUDA, O.</span>, <span class="author">BOULANGER, J.</span>, & <span class="author">BOYER, R.</span> (2021, June). Speeding Up of Kernel-Based Learning for High-Order Tensors. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2905-2909). IEEE.</p>

														<p>
															<b>Abstract:</b> Supervised learning is a major task to classify datasets. In our context, we are interested into classification from high-order tensors datasets. The "curse of dimensionality" states that the complexities in terms of storage and computation grow exponentially with the order. As a consequence, the method from the state-of-art based on the Higher-Order SVD (HOSVD) works well but suffers from severe limitations in terms of complexities.
															<br/> <br/> In this work, we propose a fast Grassmannian kernel-based method for high-order tensor learning based on the equivalence between the Tucker and the tensor-train decompositions. Our solution is linked to the tensor network, where the aim is to break the initial high-order tensor into a collection of low-order tensors (at most 3-order). We show on several real datasets that the proposed method reaches a similar accuracy classification rate as the Grassmannian kernel-based method based on the HOSVD but for a much lower complexity.
														</p>
                        </div>
                    </div>
                </article>
            </div>
            <!-- Article Ends -->

            <!-- Pagination Starts -->
            <!-- <div class="col-12 mt-4">
                <nav aria-label="Page navigation example">
                    <ul class="pagination justify-content-center mb-0">
                        <li class="page-item"><a class="page-link" href="#">1</a></li>
                        <li class="page-item active"><a class="page-link" href="#">2</a></li>
                        <li class="page-item"><a class="page-link" href="#">3</a></li>
                        <li class="page-item"><a class="page-link" href="#">4</a></li>
                    </ul>
                </nav>
            </div> -->
            <!-- Pagination Ends -->
        </div>
        <!-- Articles Ends -->
    </div>

</section>

<!-- Template JS Files -->
<script src="js/jquery-3.5.0.min.js"></script>
<script src="js/preloader.min.js"></script>
<script src="js/fm.revealator.jquery.min.js"></script>
<script src="js/imagesloaded.pkgd.min.js"></script>
<script src="js/masonry.pkgd.min.js"></script>
<script src="js/classie.js"></script>
<script src="js/cbpGridGallery.js"></script>
<script src="js/jquery.hoverdir.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.js"></script>
<script src="js/custom.js"></script>

</body>

</html>
